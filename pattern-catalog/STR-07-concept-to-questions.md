# Concept-to-Questions Decomposition

**Category**: Structure
**Necessity**: Optional

## Problem

How to systematically transform an abstract research concept into executable question items and data items?

When a research system receives an abstract topic (such as "hardware autonomy level", "social cohesion", "citizen participation"), it's unclear how to begin data collection. Abstract concepts are often vague and polysemous—different people may have completely different understandings of the same concept. Without systematic decomposition, research may:

- Miss important dimensions of the concept
- Produce questions that are too abstract to answer
- Lack coverage of the concept's full scope
- Generate inconsistent data collection standards

## Context

This pattern applies in the following scenarios:

- Research system input is an abstract concept rather than specific questions
- Need to generate concrete research checklists before data collection can begin
- Research involves complex, multi-faceted concepts
- Multiple Agents may work on different aspects of the same concept
- Research methodology needs to be explicit and reproducible

## Forces

- **Completeness vs Focus**: Covering all dimensions may dilute research focus
- **Rigor vs Practicality**: Strict decomposition takes time, but shortcuts may miss key aspects
- **Standardization vs Flexibility**: Fixed frameworks provide consistency but may not fit all concepts
- **Depth vs Breadth**: Deep analysis of one dimension vs broad coverage of many

## Solution

**Apply the two-stage "Conceptualization → Operationalization" methodology from social science research to systematically decompose abstract concepts into concrete, answerable questions.**

### The Two-Stage Process

```
Abstract Concept
    ↓ Conceptualization
Clear Definition + Identified Dimensions
    ↓ Operationalization
Concrete Question Items and Data Items
    ↓ Actual Measurement
Observable Results in the Real World
```

### Stage 1: Conceptualization

Conceptualization means clarifying the specific meaning of an abstract concept. The goal is to produce a "working definition"—not claiming to reveal the concept's "true" meaning, but establishing a clear agreement for the current research purpose.

#### Step 1.1: Clarify Multiple Meanings

Any concept worth researching usually has multiple meanings. The first step is to lay these out explicitly.

**Method**:
1. Write down your intuitive understanding of the concept
2. Consult literature to collect different scholars' definitions
3. List the different aspects the concept might contain
4. Identify similarities and differences between your understanding and others'

**Example**:

For "citizen participation", different people might understand it as:
- Number of people attending government meetings
- Number of topics citizens speak about in meetings
- Frequency of citizen letters, calls, interest group meetings

These three understandings actually correspond to three different dimensions: breadth of participation, content of participation, and forms of participation.

#### Step 1.2: Identify Dimensions

A complex concept usually consists of multiple distinguishable dimensions. Identifying these dimensions is the core work of conceptualization.

**A dimension is an independently definable aspect of a concept.**

Examples:
- "Religious piety" dimensions: belief, ritual, devotion, knowledge
- "Fear of crime" dimensions: worry frequency, perceived likelihood of victimization, perceived severity of consequences, perceived community cohesion
- "Genocide" dimensions: utilitarian (removing obstacles), retributive, fear-based, ideological

**Method**:
1. Ask yourself: What different "aspects" or "types" does this concept have?
2. Try different classification logics (see "Common Dimension Classification Logics" below)
3. Verify that each dimension is relatively independent and meaningful

#### Common Dimension Classification Logics

The following frameworks are starting points for thinking—not the only ways to classify. The specific classification logic must be determined based on the nature of the research question, the concept's connotations, and research purposes. Good dimension identification often requires combining multiple logics or creatively proposing new classifications.

##### (1) By Constituent Elements (5W1H Framework)

The most basic analytical framework, applicable to almost any concept:

| Element | Question | Example (for "citizen participation") |
|---------|----------|---------------------------------------|
| Who | Who is doing it? | Individuals, organizations, communities |
| What/Whom | Targeting what/whom? | Policy-making, elections, community affairs |
| Action | What specifically? | Voting, speaking, writing letters, protesting |
| When | When? | Routine, event-driven, periodic |
| Where | Where? | Online, offline, local, national |
| How | How? | Formal channels, informal channels |
| Why | Why? | Interest-driven, value-driven, duty-driven |

##### (2) By Internal/External or Subjective/Objective

These opposing categories are very commonly used:

| Logic | Description | Example |
|-------|-------------|---------|
| Internal vs External | Internal state vs external manifestation | Religious belief (inner conviction vs ritual behavior) |
| Subjective vs Objective | Perception/attitude vs measurable facts | Quality of life (satisfaction vs income level) |
| Form vs Substance | Surface form vs actual content | Degree of democracy (institutional form vs actual operation) |
| Willingness vs Capability | Want to vs able to | Innovation capacity (innovation willingness vs innovation resources) |

##### (3) By Process Stages

Suitable for concepts with temporal or causal structure:

| Logic | Structure | Example |
|-------|-----------|---------|
| Input-Process-Output | Resources → Activities → Results | Education quality (investment, teaching process, learning outcomes) |
| Precondition-Core-Result | Conditions → Elements → Impact | Organizational effectiveness (resource conditions, management practices, performance output) |
| Development Stages | Early → Middle → Mature | Industry development (emergence, growth, maturity, decline) |

##### (4) By Levels/Scales

Suitable for concepts involving multiple hierarchies:

| Logic | Levels | Example |
|-------|--------|---------|
| Analysis Level | Micro-Meso-Macro | Social trust (interpersonal, organizational, institutional trust) |
| Geographic Scale | Local-Regional-National-Global | Environmental governance |
| Organizational Level | Individual-Team-Organization-Industry | Innovation capability |

##### (5) By Psychological/Behavioral Structure

Suitable for concepts involving human attitudes and behaviors:

| Logic | Structure | Example |
|-------|-----------|---------|
| Cognition-Affect-Behavior | Know → Feel → Act | Environmental awareness (knowledge, attitude, behavior) |
| Knowledge-Attitude-Practice (KAP) | Understand → Agree → Execute | Health literacy |
| Awareness-Willingness-Action | Perceive → Motivate → Implement | Consumer behavior |

##### (6) By Temporal Dimension

Suitable for concepts requiring change tracking:

| Logic | Structure | Example |
|-------|-----------|---------|
| Past-Present-Future | History → Current state → Trend | Technical capability (historical accumulation, current level, development potential) |
| Static vs Dynamic | Stock vs Flow/Change | Talent reserves (existing talent vs talent mobility) |
| Short-term vs Long-term | Immediate effect vs lasting impact | Policy effects |

##### (7) By Positive/Negative or Risk

Suitable for evaluative research:

| Logic | Structure | Example |
|-------|-----------|---------|
| Strengths-Weaknesses | Advantages vs shortcomings | Competitiveness analysis |
| Opportunities-Challenges | Favorable vs unfavorable conditions | Strategic environment |
| Capability-Vulnerability | Strength vs risk exposure | Supply chain security |

#### How to Choose Classification Logic

1. **Start from the research question**: What do you most want to answer? Use "constituent elements" for describing current state, "process stages" for explaining change, "positive/negative analysis" for evaluation.

2. **Start from concept nature**: Does the concept have inherent structure? For example, "attitude" naturally has cognition-affect-behavior structure.

3. **Combine multiple approaches**: Complex research often requires using multiple classification logics simultaneously. For example, studying "hardware autonomy level" might use both "temporal dimension" (history-current-future) and "constituent elements" (capability-strategy-vulnerability).

4. **Final verification criteria**: Are the identified dimensions relatively independent? Do they cover the main connotations of the concept? Can they be grounded in observable questions?

**Key Principles**:
- Dimensions should be relatively independent, not highly overlapping
- Dimension identification should serve research purposes
- The same concept can have multiple reasonable dimension identifications

#### Step 1.3: Select Definition for Research Purpose

After identifying multiple meanings and dimensions, select a clear definition for the current research.

**Method**:
1. Based on research purpose, decide which dimensions to include and exclude
2. Write a clear "nominal definition"
3. Explain your selection rationale

**Example**:

> In this study, we define "socioeconomic status" (SES) as a manifestation of economic differences, specifically including income and education level. We do not include occupational prestige, property, lineage, lifestyle, or other possible dimensions.

This definition is not the only correct one, but it is **clear**, **operational**, and the researcher has explained its boundaries.

#### Step 1.4: Ensure Definition Practicality

A good concept definition should be **useful**, not just "correct".

**Verification criteria**:
- Can this definition help distinguish different research subjects?
- Is this definition specific enough to be transformed into observable question items?
- Can using this definition produce meaningful research findings?

### Stage 2: Operationalization

After conceptualization is complete, enter the operationalization stage—transforming clear concept definitions into concrete question items and data items.

#### Step 2.1: Determine Observable Indicators for Each Dimension

An **indicator** is an observable sign that a dimension exists or changes.

**Method**:
1. Ask yourself: If someone/some organization scores high on this dimension, what would they exhibit?
2. List all possible manifestations
3. Evaluate each manifestation's observability and accessibility

**Example**:

Dimension: "Action aspect of compassion"

Possible indicators:
- Visiting children's hospitals during holidays
- Donating to charitable organizations
- Participating in volunteer activities
- Helping strangers

#### Step 2.2: Transform Indicators into Question Items or Data Items

Indicators need to be transformed into question items (for surveys, interviews) or data items (for archives, observation) that can actually be collected.

**Considerations for Question Item Design**:

##### (1) Range of Variation

Can your question capture the complete spectrum of this variable?

- Example: Measuring attitudes toward nuclear energy, you cannot only ask "how supportive are you" (only captures positive side); you must also be able to capture "active opposition"
- Ensure coverage of the full range from positive to negative, high to low

##### (2) Degree of Precision

How fine a distinction do you need?

- Age: Need exact years, or just age brackets?
- Principle: **Better too fine than too coarse**—you can merge during analysis, but cannot split

##### (3) Level of Measurement

- Nominal: Only distinguishes categories (yes/no, Country A/Country B)
- Ordinal: Can be ranked (high/medium/low)
- Interval: Distance is meaningful (percentage, score)
- Ratio: Has a true zero point (amount, quantity)

Use higher levels of measurement when possible, as you can downgrade but not upgrade.

**Example: Question Item Design**

Dimension: "Income aspect of socioeconomic status"

Weak question item:
> Is your income high?

Strong question item:
> In the past 12 months, what was your household's total pre-tax income?
> - Under 50,000 yuan
> - 50,000-100,000 yuan
> - 100,000-200,000 yuan
> - 200,000-500,000 yuan
> - Over 500,000 yuan

#### Step 2.3: Handle Relationships Between Dimensions

When a concept has multiple dimensions, consider:

1. **Are all dimensions equally important?** If so, each dimension should have a similar number of question items
2. **Is there a hierarchical relationship between dimensions?** If so, the design needs to reflect this structure
3. **Do you need separate scores for each dimension?** Or combine into a total score?

#### Step 2.4: Verify Indicator Interchangeability

**Interchangeability principle**: If multiple indicators all point to the same dimension, they should perform consistently in distinguishing research subjects.

**Method**:
1. If according to Indicator A, women score higher than men
2. Then according to Indicators B, C, D, women should also score higher than men
3. If some indicators perform inconsistently with others, they may be measuring different dimensions

This verification can be done during pre-testing to optimize question item design.

### Output Deliverables

The decomposition process should produce structured documentation:

```
concept-decomposition/
├── concept-definition.md      # Working definition and rationale
├── dimension-analysis.md      # Identified dimensions with explanations
├── indicator-mapping.md       # Indicators for each dimension
└── question-checklist.md      # Final question items and data items
```

## Consequences

### Benefits

- **Systematic Coverage**: Ensures all important aspects of a concept are addressed
- **Explicit Methodology**: Research process is transparent and reproducible
- **Clear Scope**: Boundaries of research are well-defined
- **Measurable Outcomes**: Abstract concepts become concrete, answerable questions
- **Team Alignment**: Multiple Agents/researchers share the same understanding

### Liabilities

- **Upfront Investment**: Thorough decomposition takes significant time
- **Risk of Over-Analysis**: May produce too many dimensions and questions
- **Potential Rigidity**: Pre-defined dimensions may miss emergent aspects
- **Iteration Required**: Decomposition often needs revision during research

## Implementation Guidelines

### Integration with MAS Workflow

This pattern typically applies at the **research planning stage**, before data collection Agents begin work:

```
User Input (Abstract Concept)
    ↓
[Concept Decomposition Agent] ← This pattern
    ↓
Structured Question Checklist
    ↓
[Data Collection Agents]
    ↓
[Analysis Agents]
```

However, the pattern can also be applied **mid-research** when:
- A new sub-concept emerges that needs decomposition
- Initial decomposition proves inadequate
- Research scope expands to new areas

### Blueprint Integration

When creating an Agent that applies this pattern, include in the Blueprint:

```markdown
## Concept Decomposition Process

You will apply the Concept-to-Questions Decomposition methodology:

### Conceptualization Phase
1. Clarify multiple meanings of the target concept
2. Identify dimensions using appropriate classification logics
3. Select and document working definition

### Operationalization Phase
1. Determine observable indicators for each dimension
2. Design question items considering:
   - Range of variation (full spectrum coverage)
   - Degree of precision (fine enough for analysis)
   - Level of measurement (as high as practical)
3. Document relationships between dimensions

### Output Format
[Specify the structure for decomposition deliverables]
```

### Quality Checklist

#### Conceptualization Check
- [ ] Is the core concept clearly defined?
- [ ] Are the main dimensions identified?
- [ ] Is each dimension relatively independent and clearly bounded?
- [ ] Is there rationale for including/excluding certain dimensions?

#### Operationalization Check
- [ ] Does each dimension have corresponding question items or data items?
- [ ] Do question items cover the full range of variation?
- [ ] Is measurement precision sufficient for research needs?
- [ ] Are question items actually measuring what they intend to measure (validity)?
- [ ] Would using the same question items produce consistent results (reliability)?

#### Structure Check
- [ ] Are question items organized by dimension?
- [ ] Is the question sequence logical?
- [ ] Is there introductory text explaining research purpose?
- [ ] Are any important dimensions missing?

### Common Pitfalls

- **Skipping conceptualization**: Jumping directly to questions without clarifying what the concept means
- **Single classification logic**: Using only one framework when the concept requires multiple perspectives
- **Vague indicators**: "Good performance" instead of specific observable behaviors
- **Incomplete range**: Questions that only capture part of the spectrum
- **Over-decomposition**: Creating so many dimensions that the concept loses coherence

## Examples

### Complete Example: Operationalizing "Anomia"

This example from classic sociology shows the complete journey from abstract concept to concrete question items.

**Step 1: Concept Origin**

Durkheim proposed "anomie" in 1897 when studying suicide, referring to social norm breakdown where individuals lose behavioral guidelines. This is a social-level concept.

**Step 2: Concept Development**

Merton further developed this concept in 1938, arguing that normlessness occurs when there's a gap between social goals and means to achieve them.

Later scholars transferred the concept from social to individual level, using "anomia" to refer to individual experiences of powerlessness and meaninglessness.

**Step 3: Conceptualization—Working Definition**

Powell (1958) provided this definition:

> Anomia occurs when the goals of action become contradictory, inaccessible, or meaningless. It is characterized by a general sense of disorientation, accompanied by feelings of "emptiness" and apathy. Anomia can be simply understood as a sense of meaninglessness.

**Step 4: Operationalization—Question Item Design**

Srole (1956) published five questionnaire items that became the widely-used "Anomia Scale":

1. Despite what some people say, the lot of the average man is getting worse.
2. It's hardly fair to bring children into the world with the way things look for the future.
3. Nowadays a person has to live pretty much for today and let tomorrow take care of itself.
4. These days a person doesn't really know whom he can count on.
5. There's little use writing to public officials because often they aren't really interested in the problems of the average man.

Respondents indicate agreement or disagreement with each statement; more agreements indicate higher anomia.

**Key Points**:
- This operationalization is not the only correct approach, but it is clear and repeatable
- Studies using the same scale can be compared
- The scale has been extensively used and validated

### From industry_assessment System

**Concept**: "ESSCC Function Manifestation in an Industry"

**Conceptualization**:
- Dimension 1: Function manifestation (how does the function appear?)
- Dimension 2: Positive effects (what benefits has it brought?)
- Dimension 3: Deficiencies (where is it insufficient?)
- Dimension 4: Unique characteristics (how does this industry differ?)
- Dimension 5: Development trends (where is it heading?)

**Operationalization** (for each ESSCC functional item):
```markdown
### Question 1: Function Manifestation
**How is this ESSCC function manifested in this industry?**

Indicators:
- Specific institutional arrangements
- Policy measures
- Corporate behaviors
- Data and cases illustrating the manifestation
- Distinction between "direct" and "indirect" manifestation

### Question 2: Positive Effects
**What benefits has this manifestation brought?**

Indicators:
- Quantified achievements (scale, growth rate, market share)
- Technological progress and innovation
- Enhancement of international competitiveness
...
```

## Related Patterns

- **[Methodological Guidance](./STR-06-methodological-guidance.md)**: Complementary pattern; STR-06 addresses "how to execute research", this pattern addresses "how to define what to research"
- **[Reference Data Configuration](./STR-01-reference-data-configuration.md)**: Decomposition outputs become reference data for subsequent Agents
- **[Progressive Data Refinement](./BHV-04-progressive-data-refinement.md)**: Concept decomposition is often the first stage in progressive refinement
- **[Embedded Quality Standards](./QUA-01-embedded-quality-standards.md)**: Quality checklists in this pattern are a form of embedded standards

## References

The methodology in this pattern is primarily based on:

Babbie, E. (2013). *The Practice of Social Research* (13th ed.). Wadsworth Publishing Company.

Particularly Chapter 6 "From Concept to Measurement" and Chapter 7 "Typologies, Indexes, and Scales".
