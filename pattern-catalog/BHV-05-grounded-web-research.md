# Grounded Web Research

**Category**: Behavior
**Necessity**: Recommended

## Problem

How to correctly obtain reliable information from the web?

AI Agents have access to web search tools (such as WebSearch) and web fetch tools (such as WebFetch). A common mistake is treating search result summaries as reliable information. However, search summaries are generated by search engines or AI, often containing inaccuracies, hallucinations, or outdated information. Only content actually read from the original web page can be considered reliable data.

This problem is particularly insidious because:
- Search summaries often look authoritative and well-formatted
- The information appears to have a source (the search result includes a URL)
- AI tends to "fill in the gaps" when processing summaries, introducing further hallucinations
- By the time data enters analysis stages, fabricated information gets "laundered" into seemingly reasonable conclusions

## Context

This pattern applies when:

- Agents need to collect information from the web
- Data reliability and traceability are important
- Research outputs require verifiable sources
- Quality Assurance Level is Standard or Strict

This pattern may be skipped when:
- Quality Assurance Level is Simple
- Speed is prioritized over accuracy
- The task is exploratory and conclusions won't be cited

## Forces

- **Speed vs Accuracy**: Using search summaries directly is faster, but less reliable
- **Convenience vs Rigor**: Summaries are readily available, but original content requires additional fetching
- **Coverage vs Depth**: Search can find many sources quickly, but verifying each takes time
- **Automation vs Verification**: Fully automated collection is efficient, but may propagate errors

## Solution

**Treat web search results only as leads, not as data. Always fetch and read the original web page content before using any information. Only information extracted from the actual page content can be recorded as collected data.**

### The Two-Tool Distinction

| Tool | Purpose | Output Reliability | Use Case |
|------|---------|-------------------|----------|
| **WebSearch** | Find potentially relevant URLs | **Low** - summaries are unreliable | Discovering sources, getting leads |
| **WebFetch** | Retrieve actual page content | **High** - original content | Extracting usable information |

### Core Principles

1. **Search Results Are Leads, Not Data**
   - WebSearch returns URLs and summaries
   - Summaries may be inaccurate, outdated, or hallucinated
   - Never quote or cite information from search summaries directly

2. **Fetch Before You Use**
   - Every piece of information must come from WebFetch content
   - Read the actual page before extracting any facts
   - If a page cannot be fetched, that information cannot be used

3. **Extract From Original Content**
   - After fetching, carefully read the page content
   - Extract specific facts, quotes, and data points
   - Preserve the exact wording for important claims

4. **Document the Source Precisely**
   - Record the URL that was actually fetched
   - Note the fetch timestamp
   - Quote relevant passages from the original

### Correct Workflow

```
Step 1: Search for Leads
        │
        │  WebSearch("topic keywords")
        │
        ▼
Step 2: Review Search Results
        │
        │  Identify promising URLs from results
        │  (Ignore the summary text!)
        │
        ▼
Step 3: Fetch Original Content
        │
        │  WebFetch(url) for each promising URL
        │
        ▼
Step 4: Extract Information
        │
        │  Read the fetched content carefully
        │  Extract relevant facts and quotes
        │
        ▼
Step 5: Record with Source
        │
        │  Document: URL, fetch time, extracted content
        │
        ▼
[Usable Data]
```

## Consequences

### Benefits

- **Reliable Data**: Information comes from verifiable original sources
- **Reduced Hallucination**: Eliminates the "summary hallucination" problem
- **Traceable Claims**: Every fact can be traced to its source page
- **Verifiable**: Others can fetch the same URL and verify the information
- **Supports QUA-03**: Clean integration with Verifiable Data Lineage pattern

### Liabilities

- **Slower Collection**: Fetching each page takes additional time
- **More API Calls**: Each URL requires a separate fetch operation
- **Some Pages Inaccessible**: Paywalls, dynamic content, or errors may block access
- **Higher Token Usage**: Processing full page content uses more tokens than summaries

## Implementation Guidelines

### Blueprint Language for Data Collection Agents

```markdown
## Web Research Method

When collecting information from the web:

### Step 1: Search for Sources
Use WebSearch to find potentially relevant pages. The search results give you
**URLs to investigate**, not facts to use directly.

**Important**: Search result summaries are NOT reliable. Do not quote or use
information from these summaries. They are only for identifying which URLs
to fetch.

### Step 2: Fetch and Read Original Content
For each promising URL from search results:
1. Use WebFetch to retrieve the actual page content
2. Read the fetched content carefully
3. Extract specific information from what you read

### Step 3: Record Information with Sources
When recording collected information:
- Quote the exact text from the original page
- Record the URL you fetched
- Note the collection timestamp
- Assess source credibility

### What NOT to Do
- ❌ Do not cite information from search summaries
- ❌ Do not assume search snippets are accurate
- ❌ Do not use information from pages you couldn't fetch
- ❌ Do not paraphrase without fetching the original
```

### Handling Inaccessible Pages

```markdown
## When Pages Cannot Be Fetched

If WebFetch fails for a URL:
1. Try an alternative URL for the same information
2. Search for other sources covering the same topic
3. If no accessible source exists, **do not use that information**

Never fall back to using the search summary when a page cannot be fetched.
The correct response is to find another source or acknowledge the gap.
```

### Data Recording Format

```markdown
## [SRC-XXX] Data Title

**Source URL**: [The URL that was actually fetched]
**Fetch Time**: [When WebFetch was performed]
**Source Type**: [Academic Article / Policy Document / News Report / ...]
**Publication Date**: [If available from the page]

**Extracted Content**:
[Information extracted from the fetched page content]

**Key Quote from Original**:
> "[Exact quote from the page]"

**Credibility Assessment**: [High / Medium / Low]
**Assessment Basis**: [Why this credibility level]
```

## Examples

### Correct Example

```markdown
Task: Find the market size of the electric vehicle industry in China

Step 1: WebSearch("China electric vehicle market size 2024")
→ Results include several URLs with summary snippets

Step 2: Identify promising sources
→ Found URL from China Association of Automobile Manufacturers

Step 3: WebFetch("https://www.caam.org.cn/...")
→ Retrieved full page content

Step 4: Extract from fetched content
→ Page states: "In 2024, new energy vehicle sales reached 9.49 million units"

Step 5: Record with source
## [SRC-001] China NEV Sales 2024

**Source URL**: https://www.caam.org.cn/chn/4/cate_32/con_5236621.html
**Fetch Time**: 2025-03-15 10:30 UTC
**Source Type**: Industry Association Official Data

**Extracted Content**:
According to CAAM official statistics, China's new energy vehicle sales
in 2024 reached 9.49 million units.

**Key Quote from Original**:
> "2024年，新能源汽车销量达到949万辆"
```

### Incorrect Example

```markdown
❌ WRONG: Using search summary directly

Task: Find the market size of the electric vehicle industry in China

WebSearch("China electric vehicle market size 2024")
→ Summary says: "The market reached $150 billion in 2024"

Recording directly from summary:
"The China EV market reached $150 billion in 2024 [Source: web search]"

Problems:
1. The $150 billion figure was never verified from the original page
2. The summary might be outdated, incorrect, or hallucinated
3. No actual page was fetched to confirm this
4. Source is vague ("web search" is not a real source)
```

### Handling Search Result Hallucinations

A common scenario where this pattern prevents errors:

```markdown
WebSearch returns a summary claiming:
"According to Ministry of Industry report, EV subsidies will increase 50% in 2025"

Without this pattern: Agent records this as fact
With this pattern: Agent fetches the Ministry page, discovers:
- The page doesn't mention 50% increase
- The actual announcement discusses subsidy phase-out
- The search summary was a hallucination or outdated

Result: Correct information recorded instead of fabricated claim
```

## Quality Level Integration

| Quality Level | Grounded Web Research Requirement |
|--------------|-----------------------------------|
| **Simple** | Optional - may use search summaries for speed |
| **Standard** | Required - must fetch before using |
| **Strict** | Required - must fetch and cross-verify |

In Standard and Strict modes, the Orchestrator should verify that data collection agents are following the fetch-before-use principle by checking that recorded sources include fetch timestamps and quoted original content.

## Related Patterns

- **[Intelligent Runtime](./COR-02-intelligent-runtime.md)**: Provides WebSearch and WebFetch tools
- **[Methodological Guidance](./STR-06-methodological-guidance.md)**: Defines what types of sources are credible (orthogonal to how they are obtained)
- **[Verifiable Data Lineage](./QUA-03-verifiable-data-lineage.md)**: Requires traceable sources; this pattern ensures sources are real
- **[Embedded Quality Standards](./QUA-01-embedded-quality-standards.md)**: Data collection standards should include fetch requirements

## Checklist

When designing data collection agents, confirm:

- [ ] Blueprint explicitly states that search summaries are not reliable data?
- [ ] Blueprint requires WebFetch before using any web information?
- [ ] Data recording format includes fetch timestamp?
- [ ] Data recording format includes quoted original content?
- [ ] Instructions for handling inaccessible pages are provided?
- [ ] Agent knows not to fall back to summaries when fetch fails?
