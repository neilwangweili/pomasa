# Grounded Web Research

**Category**: Behavior
**Necessity**: Recommended

## Problem

How to correctly obtain reliable information from the web?

AI Agents have access to web search tools (such as WebSearch) and web fetch tools (such as WebFetch). A common mistake is treating search result summaries as reliable information. However, search summaries are generated by search engines or AI, often containing inaccuracies, hallucinations, or outdated information. Only content actually read from the original web page can be considered reliable data.

This problem is particularly insidious because:
- Search summaries often look authoritative and well-formatted
- The information appears to have a source (the search result includes a URL)
- AI tends to "fill in the gaps" when processing summaries, introducing further hallucinations
- By the time data enters analysis stages, fabricated information gets "laundered" into seemingly reasonable conclusions

A secondary problem arises when agents attempt to summarize or extract information during the collection phase. This introduces another layer of potential distortion:
- The collecting agent may misunderstand or misinterpret the content
- Important details may be lost in summarization
- The summary becomes a "second-hand source" that downstream agents must trust
- Analysis agents cannot verify claims against the original if only summaries are preserved

## Context

This pattern applies when:

- Agents need to collect information from the web
- Data reliability and traceability are important
- Research outputs require verifiable sources
- Quality Assurance Level is Standard or Strict

This pattern may be skipped when:
- Quality Assurance Level is Simple
- Speed is prioritized over accuracy
- The task is exploratory and conclusions won't be cited

## Forces

- **Speed vs Accuracy**: Using search summaries directly is faster, but less reliable
- **Convenience vs Rigor**: Summaries are readily available, but original content requires additional fetching
- **Coverage vs Depth**: Search can find many sources quickly, but verifying each takes time
- **Storage vs Fidelity**: Saving full content uses more space, but preserves all information
- **Separation of Concerns**: Collection agents should collect; analysis agents should analyze

## Solution

**Treat web search results only as leads, not as data. Always fetch the original web page content and preserve it in full. Do not summarize, extract, or interpret content during the collection phase—save the complete original content and leave analysis to downstream agents.**

### The Two-Tool Distinction

| Tool | Purpose | Output Reliability | Use Case |
|------|---------|-------------------|----------|
| **WebSearch** | Find potentially relevant URLs | **Low** - summaries are unreliable | Discovering sources, getting leads |
| **WebFetch** | Retrieve actual page content | **High** - original content | Obtaining content to preserve |

### Core Principles

1. **Search Results Are Leads, Not Data**
   - WebSearch returns URLs and summaries
   - Summaries may be inaccurate, outdated, or hallucinated
   - Never quote or cite information from search summaries directly

2. **Fetch Before You Save**
   - Every piece of information must come from WebFetch content
   - If a page cannot be fetched, that information cannot be used

3. **Preserve Original Content in Full**
   - Save the complete fetched content without modification
   - Do not summarize, paraphrase, or extract during collection
   - Analysis and interpretation belong to a later phase
   - This ensures downstream agents work with primary sources, not second-hand summaries

4. **Document the Source Precisely**
   - Record the URL that was actually fetched
   - Note the fetch timestamp
   - Record source type and credibility assessment based on the source (not the content)

### Why Preserve Full Content?

Separating collection from analysis provides several advantages:

1. **No Information Loss**: Summaries inevitably lose details; full content preserves everything
2. **No Interpretation Bias**: Collection agents may misunderstand content; saving verbatim avoids this
3. **Verifiable by Downstream Agents**: Analysis agents can verify any claim against the original
4. **Reusable for Different Analyses**: The same source can support multiple analytical perspectives
5. **Clear Responsibility**: Collection agents are responsible for obtaining reliable sources; analysis agents are responsible for understanding them

### Correct Workflow

```
Step 1: Search for Leads
        │
        │  WebSearch("topic keywords")
        │
        ▼
Step 2: Review Search Results
        │
        │  Identify promising URLs from results
        │  (Ignore the summary text!)
        │
        ▼
Step 3: Fetch Original Content
        │
        │  WebFetch(url) for each promising URL
        │
        ▼
Step 4: Save Complete Content
        │
        │  Preserve the full fetched content
        │  Add metadata (URL, timestamp, source type)
        │  Do NOT summarize or extract
        │
        ▼
[Raw Data Ready for Analysis]
```

## Consequences

### Benefits

- **Reliable Data**: Information comes from verifiable original sources
- **Reduced Hallucination**: Eliminates both "summary hallucination" and "extraction distortion"
- **Traceable Claims**: Every fact can be traced to its source page
- **Verifiable**: Downstream agents can verify any claim against the preserved original
- **Separation of Concerns**: Collection and analysis are cleanly separated responsibilities
- **Supports QUA-03**: Clean integration with Verifiable Data Lineage pattern

### Liabilities

- **Slower Collection**: Fetching each page takes additional time
- **More API Calls**: Each URL requires a separate fetch operation
- **Some Pages Inaccessible**: Paywalls, dynamic content, or errors may block access
- **Higher Storage Usage**: Full content takes more space than summaries
- **Higher Token Usage**: Analysis agents must process full content (but this is appropriate—they need it anyway)

## Implementation Guidelines

### Blueprint Language for Data Collection Agents

```markdown
## Web Research Method

When collecting information from the web:

### Step 1: Search for Sources
Use WebSearch to find potentially relevant pages. The search results give you
**URLs to investigate**, not facts to use directly.

**Important**: Search result summaries are NOT reliable. Do not quote or use
information from these summaries. They are only for identifying which URLs
to fetch.

### Step 2: Fetch Original Content
For each promising URL from search results:
1. Use WebFetch to retrieve the actual page content
2. Verify the fetch was successful

### Step 3: Save Complete Content with Metadata
Save the fetched content in full:
- Preserve the complete original content without modification
- Record the URL you fetched
- Note the collection timestamp
- Assess source credibility (based on the source, not the content)

**Important**: Do NOT summarize, paraphrase, or extract key points. Save the
complete content. Analysis will be performed by downstream agents who need
access to the full original.

### What NOT to Do
- ❌ Do not cite information from search summaries
- ❌ Do not assume search snippets are accurate
- ❌ Do not use information from pages you couldn't fetch
- ❌ Do not summarize or paraphrase the fetched content
- ❌ Do not extract "key points" or "relevant sections"
- ❌ Do not interpret or analyze during collection
```

### Handling Inaccessible Pages

```markdown
## When Pages Cannot Be Fetched

If WebFetch fails for a URL:
1. Try an alternative URL for the same information
2. Search for other sources covering the same topic
3. If no accessible source exists, **do not use that information**

Never fall back to using the search summary when a page cannot be fetched.
The correct response is to find another source or acknowledge the gap.
```

### Data Recording Format

```markdown
## [SRC-XXX] Source Title

**Source URL**: [The URL that was actually fetched]
**Fetch Time**: [When WebFetch was performed]
**Source Type**: [Academic Article / Policy Document / News Report / ...]
**Credibility**: [High / Medium / Low - based on source authority, not content]

**Original Content**:

[Complete content from WebFetch, preserved verbatim]
```

Note: The format is intentionally minimal. No "extracted content", "key quotes", or "relevance assessment" fields—these require interpretation and belong to the analysis phase.

## Examples

### Correct Example

```markdown
Task: Collect information about electric vehicle policies in China

Step 1: WebSearch("China electric vehicle policy 2024")
→ Results include several URLs with summary snippets

Step 2: Identify promising sources
→ Found URL from Ministry of Industry and Information Technology

Step 3: WebFetch("https://www.miit.gov.cn/...")
→ Retrieved full page content

Step 4: Save complete content
## [SRC-001] MIIT New Energy Vehicle Policy Announcement

**Source URL**: https://www.miit.gov.cn/jgsj/zbys/qcgy/art/2024/art_xxx.html
**Fetch Time**: 2025-03-15 10:30 UTC
**Source Type**: Government Policy Document
**Credibility**: High (official government website)

**Original Content**:

工业和信息化部关于进一步促进新能源汽车产业发展的通知

各省、自治区、直辖市及计划单列市工业和信息化主管部门：

为深入贯彻落实党中央、国务院关于碳达峰碳中和的重大战略决策，
加快推动新能源汽车产业高质量发展，现就有关事项通知如下：

一、总体要求
[... complete document content preserved verbatim ...]
```

### Incorrect Example

```markdown
❌ WRONG: Summarizing during collection

Task: Collect information about electric vehicle policies in China

WebFetch("https://www.miit.gov.cn/...")
→ Retrieved full page content

Recording with summary:
## [SRC-001] MIIT NEV Policy

**Source URL**: https://www.miit.gov.cn/...
**Fetch Time**: 2025-03-15 10:30 UTC

**Key Points**:
- The policy aims to promote NEV development
- Subsidies will continue until 2025
- Focus on charging infrastructure

**Relevant Quote**:
> "加快推动新能源汽车产业高质量发展"

Problems:
1. "Key Points" are the collector's interpretation, may miss important details
2. Downstream agents cannot verify if the summary is accurate
3. Information not in "Key Points" is effectively lost
4. The collector made analytical judgments that should be left to analysts
```

### Incorrect Example: Using Search Summary

```markdown
❌ WRONG: Using search summary directly

WebSearch("China electric vehicle market size 2024")
→ Summary says: "The market reached $150 billion in 2024"

Recording directly from summary:
"The China EV market reached $150 billion in 2024 [Source: web search]"

Problems:
1. The $150 billion figure was never verified from the original page
2. The summary might be outdated, incorrect, or hallucinated
3. No actual page was fetched to confirm this
4. Source is vague ("web search" is not a real source)
```

## Quality Level Integration

| Quality Level | Grounded Web Research Requirement |
|--------------|-----------------------------------|
| **Simple** | Optional - may use search summaries for speed |
| **Standard** | Required - must fetch and preserve full content |
| **Strict** | Required - must fetch, preserve full content, and cross-verify with multiple sources |

In Standard and Strict modes, the Orchestrator should verify that data collection agents are preserving complete original content by checking that:
- Recorded sources include fetch timestamps
- Original content field contains substantial text (not summaries)
- No "extracted" or "key points" fields that suggest summarization occurred

## Related Patterns

- **[Intelligent Runtime](./COR-02-intelligent-runtime.md)**: Provides WebSearch and WebFetch tools
- **[Methodological Guidance](./STR-06-methodological-guidance.md)**: Defines what types of sources are credible (orthogonal to how they are obtained)
- **[Verifiable Data Lineage](./QUA-03-verifiable-data-lineage.md)**: Requires traceable sources; this pattern ensures sources are real and complete
- **[Embedded Quality Standards](./QUA-01-embedded-quality-standards.md)**: Data collection standards should include preservation requirements
- **[Progressive Data Refinement](./BHV-04-progressive-data-refinement.md)**: Analysis and refinement happen after collection, not during

## Checklist

When designing data collection agents, confirm:

- [ ] Blueprint explicitly states that search summaries are not reliable data?
- [ ] Blueprint requires WebFetch before saving any web information?
- [ ] Blueprint explicitly prohibits summarizing or extracting during collection?
- [ ] Data recording format preserves complete original content?
- [ ] Data recording format includes fetch timestamp?
- [ ] Data recording format does NOT include interpretation fields (key points, relevance, etc.)?
- [ ] Instructions for handling inaccessible pages are provided?
- [ ] Agent knows not to fall back to summaries when fetch fails?
